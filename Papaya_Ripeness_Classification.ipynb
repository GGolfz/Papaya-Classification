{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Papaya Ripeness Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m7t6TbjnK7G"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-9uec8EdoL"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktRDq7Qst1Fp"
      },
      "source": [
        "import gdown\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8VTyXzVcMvt"
      },
      "source": [
        "# Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXy-UMSdcPLi"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R30BfdDJaWiF"
      },
      "source": [
        "# Image Rename (DON'T NEED TO RUN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVshB3hQaZKd"
      },
      "source": [
        "i = 1\n",
        "for name in os.listdir('/content/gdrive/MyDrive/CSC340 AI/Datasets/Mature'):\n",
        "  new_name = 'mature_'+str(i).zfill(4)+'.'+name.split('.')[len(name.split('.'))-1]\n",
        "  i+=1\n",
        "  shutil.move('/content/gdrive/MyDrive/CSC340 AI/Datasets/Mature/'+name,'/content/gdrive/MyDrive/CSC340 AI/Datasets/Mature/'+new_name)\n",
        "i = 1\n",
        "for name in os.listdir('/content/gdrive/MyDrive/CSC340 AI/Datasets/Partially Mature'):\n",
        "  new_name = 'partiallymature_'+str(i).zfill(4)+'.'+name.split('.')[len(name.split('.'))-1]\n",
        "  i+=1\n",
        "  shutil.move('/content/gdrive/MyDrive/CSC340 AI/Datasets/Partially Mature/'+name,'/content/gdrive/MyDrive/CSC340 AI/Datasets/Partially Mature/'+new_name)\n",
        "i = 1\n",
        "for name in os.listdir('/content/gdrive/MyDrive/CSC340 AI/Datasets/Unmature'):\n",
        "  new_name = 'unmature_'+str(i).zfill(4)+'.'+name.split('.')[len(name.split('.'))-1]\n",
        "  i+=1\n",
        "  shutil.move('/content/gdrive/MyDrive/CSC340 AI/Datasets/Unmature/'+name,'/content/gdrive/MyDrive/CSC340 AI/Datasets/Unmature/'+new_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpAaL0izeGXM"
      },
      "source": [
        "## Image Augmentation (DON'T NEED TO RUN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMnfyDSCeB4l"
      },
      "source": [
        "import tensorflow.keras.layers.experimental.preprocessing as prep\n",
        "data_gen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=60,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.1,\n",
        "      zoom_range=0.2,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eyyvn-Ypmjb5"
      },
      "source": [
        "base='/content/gdrive/MyDrive/CSC340 AI/Datasets'\n",
        "def augmented_img(path):\n",
        "  count = 0\n",
        "  filelist = os.listdir(base+'/'+path)\n",
        "  max = len(filelist)\n",
        "  print(max, filelist)\n",
        "  for i in filelist:\n",
        "    img = plt.imread(base+'/'+path+'/'+i,0)\n",
        "    img = tf.expand_dims(img, 0)\n",
        "    data_gen.fit(img)\n",
        "    extension = i.split('.')\n",
        "    extension = extension[len(extension)-1]\n",
        "    for x, val in zip(data_gen.flow(img,save_to_dir=base+'/'+path,save_prefix='aug',save_format=extension),range(10)):pass\n",
        "    count+=1\n",
        "    print(path+': '+str(count)+'/'+str(max))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFxcxD5UFHB7"
      },
      "source": [
        "augmented_img('Mature')\n",
        "augmented_img('Partially Mature')\n",
        "augmented_img('Unmature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCt4VT4-nS0S"
      },
      "source": [
        "# Import Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ft-bmNYpBu2T"
      },
      "source": [
        "## Download Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1WeMyS7BqBv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9f3821cf-59d9-4660-ca48-fb24f7ea8c6c"
      },
      "source": [
        "url = \"https://drive.google.com/uc?id=1bJaxLQIzgUIrMhoh1kJ0UAJqoVQ0K93F\"\n",
        "output = \"papaya_image.zip\"\n",
        "gdown.download(url,output,quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1bJaxLQIzgUIrMhoh1kJ0UAJqoVQ0K93F\n",
            "To: /content/papaya_image.zip\n",
            "1.73GB [00:29, 57.8MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'papaya_image.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2UQvL_j1PHO"
      },
      "source": [
        "!unzip papaya_image.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8-TWGKJJghR"
      },
      "source": [
        "!rm -rf papaya_image.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EZyGEVPoUne"
      },
      "source": [
        "# Train Validate Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ0fXRRxuhLh"
      },
      "source": [
        "### Define directory path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWfxpfc-oZF6"
      },
      "source": [
        "root_dir = './'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYzvU3STpI88"
      },
      "source": [
        "base_dir = os.path.join(root_dir,'Datasets')\n",
        "raw_mature_dir = os.path.join(base_dir,'Mature')\n",
        "raw_partially_dir = os.path.join(base_dir,'Partially Mature')\n",
        "raw_unmature_dir = os.path.join(base_dir,'Unmature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qqc1pbTpMx9"
      },
      "source": [
        "train_dir = os.path.join(base_dir,'train')\n",
        "train_mature_dir = os.path.join(train_dir,'Mature')\n",
        "train_partially_mature_dir = os.path.join(train_dir,'Partially Mature')\n",
        "train_unmature_dir = os.path.join(train_dir,'Unmature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNQX_YMKpOwh"
      },
      "source": [
        "validate_dir = os.path.join(base_dir,'validate')\n",
        "validate_mature_dir = os.path.join(validate_dir,'Mature')\n",
        "validate_partially_mature_dir = os.path.join(validate_dir,'Partially Mature')\n",
        "validate_unmature_dir = os.path.join(validate_dir,'Unmature')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSntbde4ubNO"
      },
      "source": [
        "### Create directory for train and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbfzLyfwsu8F"
      },
      "source": [
        "os.mkdir(train_dir)\n",
        "os.mkdir(train_mature_dir)\n",
        "os.mkdir(train_partially_mature_dir)\n",
        "os.mkdir(train_unmature_dir)\n",
        "os.mkdir(validate_dir)\n",
        "os.mkdir(validate_mature_dir)\n",
        "os.mkdir(validate_partially_mature_dir)\n",
        "os.mkdir(validate_unmature_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5L024JrukuX"
      },
      "source": [
        "### Train and validate split and copy file to target directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m6Hg4tgpSf4"
      },
      "source": [
        "train_size = 0.75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLQJuuKcpWex"
      },
      "source": [
        "mature_df = pd.DataFrame(data=os.listdir(raw_mature_dir),columns=[\"filename\"])\n",
        "partially_mature_df = pd.DataFrame(data=os.listdir(raw_partially_dir),columns=[\"filename\"])\n",
        "unmature_df = pd.DataFrame(data=os.listdir(raw_unmature_dir),columns=[\"filename\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_knSCuq9qiT3"
      },
      "source": [
        "mature_train_df, mature_validate_df = train_test_split(mature_df,train_size=train_size,random_state=42)\n",
        "partially_mature_train_df, partially_mature_validate_df = train_test_split(partially_mature_df,train_size=train_size,random_state=42)\n",
        "unmature_train_df, unmature_validate_df = train_test_split(unmature_df,train_size=train_size,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSXIax-pJ3Bk"
      },
      "source": [
        "mature_train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaGMtsqDsV7z"
      },
      "source": [
        "for file in mature_train_df.itertuples():\n",
        "  shutil.copyfile(os.path.join(raw_mature_dir,file[1]),os.path.join(train_mature_dir,file[1]))\n",
        "for file in partially_mature_train_df.itertuples():\n",
        "  shutil.copyfile(os.path.join(raw_partially_dir,file[1]),os.path.join(train_partially_mature_dir,file[1]))\n",
        "for file in unmature_train_df.itertuples():\n",
        "  shutil.copyfile(os.path.join(raw_unmature_dir,file[1]),os.path.join(train_unmature_dir,file[1]))\n",
        "for file in mature_validate_df.itertuples():\n",
        "  shutil.copyfile(os.path.join(raw_mature_dir,file[1]),os.path.join(validate_mature_dir,file[1]))\n",
        "for file in partially_mature_validate_df.itertuples():\n",
        "  shutil.copyfile(os.path.join(raw_partially_dir,file[1]),os.path.join(validate_partially_mature_dir,file[1]))\n",
        "for file in unmature_validate_df.itertuples():\n",
        "  shutil.copyfile(os.path.join(raw_unmature_dir,file[1]),os.path.join(validate_unmature_dir,file[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yux6wZHk7yvX"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhxXbsBOuZe2"
      },
      "source": [
        "# For our CNN\n",
        "IMAGE_SIZE = 300\n",
        "BATCH_SIZE = 100\n",
        "model_name = 'model_vgg.h5'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMPigcYZ8Naq"
      },
      "source": [
        "def showImage(img):\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hrqx84S8nqR"
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=60,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXw89CHH8470"
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     class_mode=\"categorical\",\n",
        "                                                     target_size=(IMAGE_SIZE,IMAGE_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag8ONIRv8_YD"
      },
      "source": [
        "sample_image = train_data_gen[0][0][0]\n",
        "showImage(sample_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwwgqJZXEPOE"
      },
      "source": [
        "train_data_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSZklofO9yhM"
      },
      "source": [
        "image_gen_val = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=60,\n",
        "      horizontal_flip=True,\n",
        "      vertical_flip=True,\n",
        "      fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an_Mg2dz-IqH"
      },
      "source": [
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=BATCH_SIZE,\n",
        "                                                 directory=validate_dir,\n",
        "                                                 class_mode=\"categorical\",\n",
        "                                                 target_size=(IMAGE_SIZE, IMAGE_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Tr_w2FEWij"
      },
      "source": [
        "val_data_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy0xGAjhA8bP"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4wr4TWpBBwo"
      },
      "source": [
        "## Construct Model (CNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kImOVkjf-uxe"
      },
      "source": [
        "def getCNNModel():\n",
        "  global IMAGE_SIZE\n",
        "  IMAGE_SIZE = 300\n",
        "  global model_name\n",
        "  model_name = \"model_cnn.h5\"\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Dropout(0.5),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(3)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAtG_hwWEyQI"
      },
      "source": [
        "## Construct Model with Pretrained VGG Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5XqHoM5Ex96"
      },
      "source": [
        "def getVGGModel():\n",
        "  global IMAGE_SIZE\n",
        "  IMAGE_SIZE = 224\n",
        "  global model_name\n",
        "  model_name = \"model_vgg.h5\"\n",
        "  from tensorflow.keras.applications import VGG16\n",
        "  from tensorflow.keras.layers import Flatten,Dense\n",
        "  from tensorflow.keras import Model\n",
        "  vgg = VGG16(input_shape=[IMAGE_SIZE,IMAGE_SIZE,3], weights='imagenet', include_top=False)\n",
        "  x = Flatten()(vgg.output)\n",
        "  predict = Dense(3, activation='softmax')(x)\n",
        "  model = Model(inputs=vgg.input, outputs=predict)\n",
        "  return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwCC-Qn0ZEGO"
      },
      "source": [
        "# Construct Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BydDdTEeZmhX"
      },
      "source": [
        "def getModel(model_name):\n",
        "  if model_name == 'CNN':\n",
        "    return getCNNModel()\n",
        "  elif model_name == 'VGG':\n",
        "    return getVGGModel()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgOoSfvqYy7v"
      },
      "source": [
        "model_name = \"CNN\" #@param [\"CNN\", \"VGG\"]\n",
        "model = getModel(model_name)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9-bqB_BadgK"
      },
      "source": [
        "model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6ZzeA7DMFrl"
      },
      "source": [
        "## Compile model & Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFMJ4UHR_A_u"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcyClfTiazM6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpCOt2QeA_Q_"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "100jiikV_W-Q"
      },
      "source": [
        "total_train = len(mature_train_df) + len(partially_mature_train_df) + len(unmature_train_df)\n",
        "total_validate = len(mature_validate_df) + len(partially_mature_validate_df) + len(unmature_validate_df)\n",
        "epochs = 35\n",
        "patience = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agP9_r_4_1M9"
      },
      "source": [
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_name, save_best_only=True)\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(patience=patience)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMKZt3D8ABrl"
      },
      "source": [
        "history = model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJxmvoNzBaHg"
      },
      "source": [
        "## Plot Model Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqxuhXJ2AJMU"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(20)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z__WXbrTGXG"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeoTj__lBWnS"
      },
      "source": [
        "## Load Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YmuCTERAHgx"
      },
      "source": [
        "model = tf.keras.models.load_model(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUF4ojzALOQ"
      },
      "source": [
        "class_labels = [\"mature\", \"partially mature\",\"unmature\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp_PM__dbnnw"
      },
      "source": [
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUk_zOyZYHKQ"
      },
      "source": [
        "for i in [\"/content/health-benefits-of-papaya_copy.jpeg\",\"/content/unknown.png\",\"/content/unknown (1).png\",\"/content/unknown (2).png\",\"/content/ripe.jpeg\",\"/content/Datasets/validate/Unmature/unmature_0103.JPG\"]:\n",
        "  img = tf.keras.preprocessing.image.load_img(\n",
        "      i, target_size=(IMAGE_SIZE, IMAGE_SIZE)\n",
        "  )\n",
        "  img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = img_array / 255\n",
        "  img_array = img_array.reshape(1,IMAGE_SIZE,IMAGE_SIZE,3)\n",
        "  predictions = model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "  imgplot = plt.imshow(img)\n",
        "  plt.show()\n",
        "  print(\n",
        "      \"This image most likely belongs to {} \"\n",
        "      .format(class_labels[np.argmax(score)])\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrF7D5JiV9Ug"
      },
      "source": [
        "# Save Model to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTRa4ZtHZ0KX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fc8fbbe8-0a0c-410d-d49b-7b22aea0039c"
      },
      "source": [
        "shutil.copy('model_vgg.h5','/content/drive/MyDrive/CSC340 AI/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/CSC340 AI/model_vgg.h5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}